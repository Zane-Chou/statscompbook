# (PART) 现代贝叶斯计算 {-}

# 贝叶斯思维 {#bayesianthinking}

## 介绍

作为数据科学家，我们的目标是通过建立模型来理解复杂的现象。我们通常忽略一个复杂系统中与目标不直接相关的部分，这种信息的忽略这些模型更具有不确定性，因为我们对系统的某些方面是不确定的。统计建模通常有两种不同的方法：频率统计（也称为经典推理）和贝叶斯推理。本章将重点介绍贝叶斯思维的本质，同时展示两种方法之间的相似及不同之处。

通常，如果我们首先知道生成数据的过程，就可以直接计算获得不同数据样本的概率。例如，如果我们知道一枚硬币是均匀的，那么我们可以计算其正面朝上的概率（概率等于1/2）。然而，我们通常对这些数据生成过程并不完全了解，统计推断的目标是对这些机制的未知特征或参数进行估计。在我们的硬币例子中，我们可能想根据几次掷硬币的结果来推断其并不是均匀的。贝叶斯统计允许我们从已知的数据（这里是掷硬币的结果）出发，向后推断，对导致其产生过程的参数（硬币的潜在偏差）做出概率性推断。在贝叶斯统计中，这种反演过程是通过应用贝叶斯法则（Bayes' Rule）来实现的。


## 贝叶斯法则

### 条件概率和贝叶斯法则

::::{.method}
::: {.center data-latex=""}
**贝叶斯法则**
:::



事件 $B$ 发生的条件下事件 $A$ 发生的概率定义为：

$$P(A \mid B) = \frac{P(A \,\&\, B)}{P(B)}.$$
    
::::


### 贝叶斯法则和 HIV 诊断检验 {#diagtest}

为了更好地理解条件概率及其重要性，让我们考虑一个涉及艾滋病毒（HIV）的例子。上世纪80年代初，艾滋病毒被发现并迅速扩大。当时几乎没有任何治疗方法，这使艾滋病毒的诊断基本上被判死刑。这些使得 HIV 检测中的假阳性（False positives）和假阴性（False negatives）非常不受欢迎。假阳性是指测试结果为阳性，而真实值为阴性。例如，没有 HIV 的人被错误地诊断为 HIV，错误地告诉那个人他们将要死去。假阴性是指测试结果为阴性，而事实为阳性。也就是说，艾滋病病毒携带者接受了一项艾滋病毒检测，结果却错误地呈阴性。如果此人要献血，后者会对血液供应构成非常大的威胁。由此可见，假阳性和假阴性的概率都是条件概率。

我们考虑的 HIV 检测是一种叫做酶联免疫吸附试验（enzyme-linked immunosorbent assay，简称 ELISA）。我们想知道，如果 ELISA 检测阳性，某人（在1980年代早期）感染HIV的概率。为此，我们需要以下信息。ELISA 的真阳性率（1 - 假阴性率），也称为敏感度、召回率或检测概率，其估计为：

$$P(\text{其 ELISA 阳性} \mid \text{某人感染 HIV}) = 93\% = 0.93.$$
其真阴性率（1减去假阳性率），也称为特异性，估计为:

$$P(\text{其 ELISA 为阴性} \mid \text{某人未感染 HIV}) = 99\% = 0.99.$$
与我们的问题相关的还有艾滋病毒在总人口中的流行率，据估计，每1000名美国成年人中就有1.48人感染艾滋病毒。因此我们假设：

$$P(\text{感染 HIV}) = \frac{1.48}{1000} = 0.00148.$$
我们的目的是想计算如果某人 ELISA 检测为阳性的条件下其感染 HIV 的概率，也就是 $P(\text{其感染 HIV} \mid \text{某人 ELISA 阳性})$，根据贝叶斯法则：

\begin{equation}
  P(\text{其感染 HIV}  \mid \text{某人 ELISA 阳性}) = \frac{P(\text{某人感染 HIV} \,\&\, \text{其 ELISA 阳性})}{P(\text{ELISA 阳性})}.
\end{equation}

通过计算发现，所以即使 ELISA 检测结果呈阳性，感染 HIV 的概率也只有 $12\%$。这一数字如此之低的一个重要原因是艾滋病毒的感染率。在检测之前，一个人感染艾滋病毒的概率是 $0.148\%$，检测呈阳性的条件下感染 HIV 概率会发生很大的变化，但仍然低于 $50\%$。也就是说，在一次 ELISA 检测阳性后，其实未感染 HIV 的可能性更大。
这对医学诊断至关重要。正如我们所见，仅仅是检测的阳性率和阴性率并不能说明全部情况，疾病的流行率也起到了一定的作用。贝叶斯法则可以在检测结果后将这些数字综合成更有用的患病概率。

### 贝叶斯更新

在第 \@ref(diagtest) 中，我们看到，如果一次 ELISA 检测的结果为阳性，其 HIV 感染率为 $12\%$，人们可能通常需要在第一次 ELISA 检测呈阳性后进行第二次 ELISA 检测 。那么第二次检测也为阳性的条件下，这个人感染 HIV 的概率为多少呢？

在第 \@ref(diagtest) 中，我们使用 $P(\text{感染 HIV}) = 0.00148$ 计算了一次 ELISA 检测阳性后，感染 HIV 的可能性，如果我们重复这个计算过程，但是现在使用 $P(\text{感染 HIV}) = 0.12$，我们就可以得到一个人连续两次检测为阳性的条件下其感染 HIV 的概率：

\begin{align*}
  & P(\text{其感染 HIV} \mid \text{某人第二次 ELISA 阳性}) \\
  &= \frac{P(\text{感染 HIV}) P(\text{第二次 ELISA 阳性} \mid \text{某人感染 HIV})}{P(\text{第二次 ELISA 阳性})} \\
  &= \frac{0.12 \cdot 0.93}{0.12 \cdot 0.93 + (1 - 0.12)\cdot (1 - 0.99)} \approx 0.93.
\end{align*}
我们看到，两个阳性检测结果比只有一个检测结果呈阳性的情况下更容易感染艾滋病病毒。

利用贝叶斯法则根据影响概率的事件更新概率的过程称为贝叶斯更新（Bayesian updating），也叫贝叶斯学习（Bayesian learning）。更一般地说，试图更新的信息可以被认为是“先验”信息，有时简称为**先验**（prior）。提供相关信息的事件也可以是**数据**（data）。然后，使用贝叶斯法则更新这个先验信息，得到的信息是以数据为条件的，也被称为**后验**（posterior），就像在看到数据之后的信息一样。由前到后这个过程叫做贝叶斯更新，它描述的也就是 $\text{先验} + \text{数据} \rightarrow \text{后验}$ 这个过程。

### 频率学派和贝叶斯学派



## 贝叶斯推断 

贝叶斯推断是基于概率理论通过观测数据来对一个复杂系统的未知特性进行推断的过程。例如，假设我们想了解中国人口某些方面的特性，比如成年人更喜欢肯德基而不是麦当劳的人口比例，假设这个未知比例为 $\theta$。我们如何才能洞悉 $\theta$？我们可以这样做：问问人们对 $\theta$ 的看法，他们可能会相当简洁给出一些 $\theta$ 的统计分布，不同的人可能会对这个问题给出不同的答案。当然，如果我只是按照我自己的偏好给出结论说成年人更加喜欢肯德基，麦当劳公司不会太满意。相反，我们可以做一个调查来获得一些关于 $\theta$ 的更多信息，我们可以联系一些成年人，问他们是否更喜欢肯德基，并记录结果。我们有了这些数据，贝叶斯推理的目的是根据这些观测数据，对 $\theta$ 进行后验推断:

$$p(\theta|\text{data}) = \frac{p(\text{data}|\theta)p(\theta)}{p(\text{data})}.$$

### 贝叶斯推断的一般过程

贝叶斯推断一般有四个步骤：

1. **确定模型**。首先，我们需要确定统计模型，即构建似然函数，即 $p(\text{data}|\theta)$，这描述了给定特定参数 $\theta$ 下产生当前观测数据的模型机制。
2. **选择先验分布**。在拿到观测数据之前，我们对参数 $\theta$ 的先验认识，这通过概率分布 $p(\theta)$ 来描述。
3. **计算后验分布**。在拿到观测数据之后，基于贝叶斯法则计算后验分布 $p(\theta|\text{data})$，从而更新我们对 $\theta$ 的认识。
4. **推断**。通过汇总后验分布得出推断结论。

在上述过程中，最后一步其实是开放的。例如，我们可以用它来预测数据（如在监督学习中）；我们可以用各种方法（例如点估计）来对 $\theta$ 进行推断；可以用它来进行贝叶斯模型比较；可以做贝叶斯模型平均；可以来确定下一步要获得的数据（如实验的最优设计）等等。

### 单参数模型

### 多参数模型 